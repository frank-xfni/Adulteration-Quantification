{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a95480-1a7f-4fe5-a28c-a68285549222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import cdist\n",
    "def random_split(spectra, test_size=0.3, random_state=None, shuffle=True, stratify=None):\n",
    "    \"\"\"implement random_split by using sklearn.model_selection.train_test_split function. See\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "    for more infomation.\n",
    "    \"\"\"\n",
    "    return train_test_split(\n",
    "        spectra,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        shuffle=shuffle,\n",
    "        stratify=stratify)\n",
    "\n",
    "\n",
    "def kennardstone(spectra, test_size=0.2, metric='euclidean', *args, **kwargs):\n",
    "    \"\"\"Kennard Stone Sample Split method\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra: ndarray, shape of i x j\n",
    "        i spectrums and j variables (wavelength/wavenumber/ramam shift and so on)\n",
    "    test_size : float, int\n",
    "        if float, then round(i x (1-test_size)) spectrums are selected as test data, by default 0.25\n",
    "        if int, then test_size is directly used as test data size\n",
    "    metric : str, optional\n",
    "        The distance metric to use, by default 'euclidean'\n",
    "        See scipy.spatial.distance.cdist for more infomation\n",
    "    Returns\n",
    "    -------\n",
    "    select_pts: list\n",
    "        index of selected spetrums as train data, index is zero based\n",
    "    remaining_pts: list\n",
    "        index of remaining spectrums as test data, index is zero based\n",
    "    References\n",
    "    --------\n",
    "    Kennard, R. W., & Stone, L. A. (1969). Computer aided design of experiments.\n",
    "    Technometrics, 11(1), 137-148. (https://www.jstor.org/stable/1266770)\n",
    "    \"\"\"\n",
    "\n",
    "    if test_size < 1:\n",
    "        train_size = round(spectra.shape[0] * (1 - test_size))\n",
    "    else:\n",
    "        train_size = spectra.shape[0] - round(test_size)\n",
    "\n",
    "    if train_size > 2:\n",
    "        distance = cdist(spectra, spectra, metric=metric, *args, **kwargs)\n",
    "        select_pts, remaining_pts = max_min_distance_split(distance, train_size)\n",
    "    else:\n",
    "        raise ValueError(\"train sample size should be at least 2\")\n",
    "\n",
    "    return select_pts, remaining_pts\n",
    "\n",
    "\n",
    "def spxy(spectra, yvalues, test_size=0.2, metric='euclidean', *args, **kwargs):\n",
    "    \"\"\"SPXY Sample Split method\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectra: ndarray, shape of i x j\n",
    "        i spectrums and j variables (wavelength/wavenumber/ramam shift and so on)\n",
    "    test_size : float, int\n",
    "        if float, then round(i x (1-test_size)) spectrums are selected as test data, by default 0.25\n",
    "        if int, then test_size is directly used as test data size\n",
    "    metric : str, optional\n",
    "        The distance metric to use, by default 'euclidean'\n",
    "        See scipy.spatial.distance.cdist for more infomation\n",
    "    Returns\n",
    "    -------\n",
    "    select_pts: list\n",
    "        index of selected spetrums as train data, index is zero based\n",
    "    remaining_pts: list\n",
    "        index of remaining spectrums as test data, index is zero based\n",
    "    References\n",
    "    ---------\n",
    "    Galvao et al. (2005). A method for calibration and validation subset partitioning.\n",
    "    Talanta, 67(4), 736-740. (https://www.sciencedirect.com/science/article/pii/S003991400500192X)\n",
    "    \"\"\"\n",
    "\n",
    "    if test_size < 1:\n",
    "        train_size = round(spectra.shape[0] * (1 - test_size))\n",
    "    else:\n",
    "        train_size = spectra.shape[0] - round(test_size)\n",
    "\n",
    "    if train_size > 2:\n",
    "        yvalues = yvalues.reshape(yvalues.shape[0], -1)\n",
    "        distance_spectra = cdist(spectra, spectra, metric=metric, *args, **kwargs)\n",
    "        distance_y = cdist(yvalues, yvalues, metric=metric, *args, **kwargs)\n",
    "        distance_spectra = distance_spectra / distance_spectra.max()\n",
    "        distance_y = distance_y / distance_y.max()\n",
    "\n",
    "        distance = distance_spectra + distance_y\n",
    "        select_pts, remaining_pts = max_min_distance_split(distance, train_size)\n",
    "    else:\n",
    "        raise ValueError(\"train sample size should be at least 2\")\n",
    "\n",
    "    return select_pts, remaining_pts\n",
    "\n",
    "\n",
    "def max_min_distance_split(distance, train_size):\n",
    "    \"\"\"sample set split method based on maximun minimun distance, which is the core of Kennard Stone\n",
    "    method\n",
    "    Parameters\n",
    "    ----------\n",
    "    distance : distance matrix\n",
    "        semi-positive real symmetric matrix of a certain distance metric\n",
    "    train_size : train data sample size\n",
    "        should be greater than 2\n",
    "    Returns\n",
    "    -------\n",
    "    select_pts: list\n",
    "        index of selected spetrums as train data, index is zero-based\n",
    "    remaining_pts: list\n",
    "        index of remaining spectrums as test data, index is zero-based\n",
    "    \"\"\"\n",
    "\n",
    "    select_pts = []\n",
    "    remaining_pts = [x for x in range(distance.shape[0])]\n",
    "\n",
    "    # first select 2 farthest points\n",
    "    first_2pts = np.unravel_index(np.argmax(distance), distance.shape)\n",
    "    select_pts.append(first_2pts[0])\n",
    "    select_pts.append(first_2pts[1])\n",
    "\n",
    "    # remove the first 2 points from the remaining list\n",
    "    remaining_pts.remove(first_2pts[0])\n",
    "    remaining_pts.remove(first_2pts[1])\n",
    "\n",
    "    for i in range(train_size - 2):\n",
    "        # find the maximum minimum distance\n",
    "        select_distance = distance[select_pts, :]\n",
    "        min_distance = select_distance[:, remaining_pts]\n",
    "        min_distance = np.min(min_distance, axis=0)\n",
    "        max_min_distance = np.max(min_distance)\n",
    "\n",
    "        # select the first point (in case that several distances are the same, choose the first one)\n",
    "        points = np.argwhere(select_distance == max_min_distance)[:, 1].tolist()\n",
    "        for point in points:\n",
    "            if point in select_pts:\n",
    "                pass\n",
    "            else:\n",
    "                select_pts.append(point)\n",
    "                remaining_pts.remove(point)\n",
    "                break\n",
    "    return select_pts, remaining_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83453221-6e8f-44f3-b6f1-f0ad3fcead9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import IPython.display\n",
    "\n",
    "from sklearn.metrics import *  # we use global() to access the imported functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier # ExtraTreeClassifier only works in ensembles\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "# from scipy.integrate import quad\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.multivariate import manova\n",
    "from statsmodels.stats.contingency_tables import mcnemar, cochrans_q\n",
    "\n",
    "from pyNNRW.elm import ELMClassifier\n",
    "from pyNNRW.rvfl import RVFLClassifier\n",
    "\n",
    "from qsi.vis.plt2base64 import plt2html\n",
    "from qsi.vis.plot_components import plot_components_2d\n",
    "from qsi.vis.feature_importance import plot_feature_importance\n",
    "from qsi.vis.unsupervised_dimension_reductions import unsupervised_dimension_reductions\n",
    "from cla.vis.confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import top_k_accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b9381-1850-4d6f-8233-8e125439c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm0_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d59507-bd45-4bbc-8b70-dfe828bf18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62dc47-4685-49a8-8f2d-0b9dab352ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebdd98-a7ae-40ba-a6d6-0b79bb5c54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm0.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm0.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm0.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm0.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm0.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm0.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98a6ac-27ff-40a1-beb0-78fcd9d6260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm20_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a67d6-c079-4a9d-af43-7bfbf98cfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24e355-d92d-44c8-90e5-bef7fc705fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edb425-6318-473f-8b6e-2443d52cee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm20.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm20.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm20.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm20.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm20.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm20.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad92b2cf-bc90-4068-ad7b-9c20d9716cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm40_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d8ef6-de5b-4a64-8295-1a9dfff0d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4899e8-4ddf-4dda-9b98-c4a4c65c52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c2b5d-48fc-422a-8d69-2021f7ac2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm40.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm40.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm40.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm40.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm40.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm40.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7c6d4-2139-4f51-8298-7d8212af064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm60_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5230b-1b7a-4136-b9c4-33da2b083f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f6ef9-50b3-44b5-9d98-ea11dee7af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea9461-22d1-4d09-b7f4-6a6192c326cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm60.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm60.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm60.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm60.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm60.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm60.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d900c0e-a155-46e7-9235-0bbc381277be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm80_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9a6ca-b812-4210-b6f0-68a9c052a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3098b-8a64-4fcd-bcee-585e2d4527ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16feae2-6d7b-46ef-849d-5d7e9cc9db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm80.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm80.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm80.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm80.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm80.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm80.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f68dd5-caa7-4b6c-9899-40bbd50d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "\n",
    "X, y, X_names, labels = io.open_dataset('gm100_merged_data.CSV',x_range = list(range(104,1426))) # x_range = list(range(100:))\n",
    "\n",
    "from qsi import pipeline\n",
    "\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, \n",
    "                                         pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "io.draw_class_average(X, y, X_names, labels=labels, SD=1, shift=800)\n",
    "\n",
    "_ = io.scatter_plot(X, y, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1a184-12be-4ace-9d60-53d50f9dd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ea36a-1ac1-4138-ac9b-b395eea76f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi.io.pre import kennardstone_split\n",
    "import numpy as np\n",
    "\n",
    "# 第一次划分，得到校准集和测试集\n",
    "train_index, test_index = kennardstone_split(X, test_size=0.2)\n",
    "X_cal = X[train_index]\n",
    "X_test = X[test_index]\n",
    "y_cal = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "# 第二次划分，从校准集中得到训练集和验证集\n",
    "train_index, val_index = kennardstone_split(X_cal, test_size=0.1)\n",
    "X_train = X_cal[train_index]\n",
    "X_val = X_cal[val_index]\n",
    "y_train = y_cal[train_index]\n",
    "y_val = y_cal[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752aa218-b606-45c5-8907-82902ff2d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存训练集数据\n",
    "np.savetxt('gm100.train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('gm100.train_labels.csv', y_train, delimiter=',')\n",
    "\n",
    "# 保存验证集数据\n",
    "np.savetxt('gm100.val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('gm100.val_labels.csv', y_val, delimiter=',')\n",
    "\n",
    "# 保存测试集数据\n",
    "np.savetxt('gm100.test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('gm100.test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393c58a-339d-46d6-b52a-e342fba87f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = ['gm0.train_data.csv', 'gm20.train_data.csv', 'gm40.train_data.csv', 'gm60.train_data.csv', 'gm80.train_data.csv', 'gm100.train_data.csv']\n",
    "val_files = ['gm0.val_data.csv', 'gm20.val_data.csv', 'gm40.val_data.csv', 'gm60.val_data.csv', 'gm80.val_data.csv', 'gm100.val_data.csv']\n",
    "test_files = ['gm0.test_data.csv', 'gm20.test_data.csv', 'gm40.test_data.csv', 'gm60.test_data.csv', 'gm80.test_data.csv', 'gm100.test_data.csv']\n",
    "train_label_files = ['gm0.train_labels.csv', 'gm20.train_labels.csv', 'gm40.train_labels.csv', 'gm60.train_labels.csv', 'gm80.train_labels.csv', 'gm100.train_labels.csv']\n",
    "val_label_files = ['gm0.val_labels.csv', 'gm20.val_labels.csv', 'gm40.val_labels.csv', 'gm60.val_labels.csv', 'gm80.val_labels.csv', 'gm100.val_labels.csv']\n",
    "test_label_files = ['gm0.test_labels.csv', 'gm20.test_labels.csv', 'gm40.test_labels.csv', 'gm60.test_labels.csv', 'gm80.test_labels.csv', 'gm100.test_labels.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca16db8-1db3-4111-acf0-65144fc51cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_val = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []\n",
    "\n",
    "for train_file, val_file, test_file, train_label_file, val_label_file, test_label_file in zip(train_files, val_files, test_files, train_label_files, val_label_files, test_label_files):\n",
    "    train_data = np.loadtxt(train_file, delimiter=',')\n",
    "    val_data = np.loadtxt(val_file, delimiter=',')\n",
    "    test_data = np.loadtxt(test_file, delimiter=',')\n",
    "    train_labels = np.loadtxt(train_label_file, delimiter=',')\n",
    "    val_labels = np.loadtxt(val_label_file, delimiter=',')\n",
    "    test_labels = np.loadtxt(test_label_file, delimiter=',')\n",
    "\n",
    "    X_train.append(train_data)\n",
    "    X_val.append(val_data)\n",
    "    X_test.append(test_data)\n",
    "    y_train.append(train_labels)\n",
    "    y_val.append(val_labels)\n",
    "    y_test.append(test_labels)\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "X_val = np.concatenate(X_val, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "y_val = np.concatenate(y_val, axis=0)\n",
    "y_test = np.concatenate(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c8f2b-f732-498c-bf7a-a52fc078d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_val)\n",
    "print(y_val)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14fc36-3d3d-4047-b18e-86e69c0a8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('merged_train_data.csv', X_train, delimiter=',')\n",
    "np.savetxt('merged_val_data.csv', X_val, delimiter=',')\n",
    "np.savetxt('merged_test_data.csv', X_test, delimiter=',')\n",
    "np.savetxt('merged_train_labels.csv', y_train, delimiter=',')\n",
    "np.savetxt('merged_val_labels.csv', y_val, delimiter=',')\n",
    "np.savetxt('merged_test_labels.csv', y_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce02599-2fae-4919-b918-287e670b8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 指定其他字体，例如SimHei（黑体）\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95326ca0-fa2d-46a0-b3e4-3efd04bd85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsi import io\n",
    "X, yc, X_names, _, labels = io.load_dataset('gm_adulteration', x_range = list(range(104,1426)), shift=200)\n",
    "\n",
    "from qsi import pipeline\n",
    "X, X_names = pipeline.preprocess_dataset(X, X_names, pres = [('max', 0.2),('baseline_removal', (1e1, 1e-2))])\n",
    "io.draw_class_average(X, yc, X_names, labels=labels, SD=1, shift=800)\n",
    "_ = io.scatter_plot(X, yc, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe722a4-d533-48b8-b1a9-8950b9a0f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "min_raman_shift = np.min(X_names)  \n",
    "max_raman_shift = np.max(X_names)  \n",
    "print(f\"Raman Shift: min = {min_raman_shift}, max = {max_raman_shift}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3775054-7f6e-489e-b76d-6a49f8575271",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60661af-49e6-4fd6-87b6-a0cbbec42247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.asfarray(np.array(labels)[yc]) # convert class label to continuous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d23323-bcda-4291-b85d-005b6786a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# 设置全局字体大小和粗细\n",
    "rcParams.update({\n",
    "    'font.size': 15,        # 全局字体大小\n",
    "    'font.weight': 'bold',  # 全局字体粗细\n",
    "    'axes.titlesize': 16,   # 图标题字体大小\n",
    "    'axes.titleweight': 'bold',  # 图标题字体粗细\n",
    "    'axes.labelsize': 14,   # 坐标轴标签字体大小\n",
    "    'axes.labelweight': 'bold',  # 坐标轴标签字体粗细\n",
    "    'xtick.labelsize': 13,  # x轴刻度标签字体大小\n",
    "    'ytick.labelsize': 13,  # y轴刻度标签字体大小\n",
    "    'legend.fontsize': 12,  # 图例字体大小\n",
    "    'axes.linewidth': 2.0,  # 坐标轴边框线条宽度\n",
    "    'xtick.major.width': 2.0,  # x轴刻度线宽度\n",
    "    'xtick.minor.width': 2.0,  # x轴次刻度线宽度\n",
    "    'ytick.major.width': 2.0,  # y轴刻度线宽度\n",
    "    'ytick.minor.width': 2.0,  # y轴次刻度线宽度\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a17f6e-d735-4aad-bbfd-4d727bb691cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8cca6-bead-42de-835e-b0c7f536f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def draw_regression_plots(X_train, y_train, \n",
    "                          X_test, y_test, title,show_data_ticks=True, show_grid=True):\n",
    "    '''\n",
    "    X_train : 训练集真实值\n",
    "    y_train : 训练集预测值\n",
    "    X_test : 测试集真实值\n",
    "    y_test : 测试集预测值\n",
    "    title : 图表标题\n",
    "    '''\n",
    "    \n",
    "    # 将数据转换为numpy数组\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # 计算性能指标\n",
    "    r2_train = r2_score(X_train, y_train)\n",
    "    r2_test = r2_score(X_test, y_test)\n",
    "    rmse_train = np.sqrt(mean_squared_error(X_train, y_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(X_test, y_test))\n",
    "    \n",
    "    # 创建一个包含三个子图的画布\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    \n",
    "    # # 1. 按索引排列的真实值与预测值散点图\n",
    "    # plt.subplot(1, 3, 1)\n",
    "    # # plt.title(title + '\\n' + \n",
    "    # #           f'rc2 = {r2_train:.3f}, rp2 = {r2_test:.3f}, ' +\n",
    "    # #           f'RMSEC = {rmse_train:.3f}, RMSEP = {rmse_test:.3f}')\n",
    "    \n",
    "    # # # 绘制训练集数据（倒三角，红色）\n",
    "    # # plt.scatter(range(len(X_train)), X_train, marker='v', \n",
    "    # #             label='Train Ground Truth', color='red', alpha=0.5)\n",
    "    # # plt.scatter(range(len(X_train)), y_train, marker='v', \n",
    "    # #             label='Train Prediction', color='red', alpha=0.3)\n",
    "    \n",
    "    # # 绘制测试集数据（星号，蓝色）\n",
    "    # test_indices = range(len(X_train), len(X_train) + len(X_test))\n",
    "    # plt.scatter(test_indices, X_test, marker='*', \n",
    "    #             label='Test Ground Truth', color='blue', alpha=0.5)\n",
    "    # plt.scatter(test_indices, y_test, marker='*', \n",
    "    #             label='Test Prediction', color='blue', alpha=0.3)\n",
    "    # # 在右下角添加性能指标文本\n",
    "    # plt.text(0.53, 0.02, \n",
    "    #          f'$R^2$_training set = {r2_train:.3f}\\nRMSE_training set = {rmse_train:.3f}\\n$R^2$_test set = {r2_test:.3f}\\nRMSE_test set = {rmse_test:.3f}',\n",
    "    #          transform=plt.gca().transAxes, \n",
    "    #          horizontalalignment='left',\n",
    "    #          verticalalignment='bottom',\n",
    "    #          fontsize=12,\n",
    "    #          bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.5'))\n",
    "    # plt.legend()\n",
    "    # plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)\n",
    "    # plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "    # plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "    # ax = plt.gca()\n",
    "    # for spine in ax.spines.values():\n",
    "    #     spine.set_linewidth(2.0)\n",
    "\n",
    "    # # 2. 预测值 vs 真实值的对角散点图\n",
    "    # plt.subplot(1, 3, 2)\n",
    "    \n",
    "    # 绘制训练集数据\n",
    "    plt.scatter(X_train, y_train, marker='v', \n",
    "                color='red', alpha=0.5, label='Training set')\n",
    "    \n",
    "    # 绘制测试集数据\n",
    "    plt.scatter(X_test, y_test, marker='*', \n",
    "                color='blue', alpha=0.5, label='Test set')\n",
    "    \n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlim(-0.16, 1.16)\n",
    "    plt.ylim(-0.16, 1.16)\n",
    "    plt.xlabel('Actual value', fontsize=16)\n",
    "    plt.ylabel('Predicted value', fontsize=16)\n",
    "    \n",
    "    \n",
    "    # 绘制y=x参考线\n",
    "    min_val = min(min(X_train), min(X_test), min(y_train), min(y_test))\n",
    "    max_val = max(max(X_train), max(X_test), max(y_train), max(y_test))\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.plot([-0.16, 1.16], [-0.16, 1.16], 'k--', linewidth=1)\n",
    "\n",
    "\n",
    "    # 在右下角添加性能指标文本\n",
    "    plt.text(0.6, 0.05, \n",
    "             f'$R^2$_training set = {r2_train:.3f}\\nRMSE_training set = {rmse_train:.3f}\\n$R^2$_test set = {r2_test:.3f}\\nRMSE_test set = {rmse_test:.3f}',\n",
    "             transform=plt.gca().transAxes, \n",
    "             horizontalalignment='left',\n",
    "             verticalalignment='bottom',\n",
    "             fontsize=12,\n",
    "             bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)\n",
    "    plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "    plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2.0)\n",
    "\n",
    "    # # 3. 残差图（预测值与真实值的差值）\n",
    "    # plt.subplot(1, 3, 3)\n",
    "    \n",
    "    # # 计算残差\n",
    "    # residuals_train = y_train.flatten() - X_train.flatten()\n",
    "    # residuals_test = y_test.flatten() - X_test.flatten()\n",
    "    \n",
    "    \n",
    "    # # 绘制测试集残差\n",
    "    # plt.scatter(X_test.flatten(), residuals_test, marker='*', \n",
    "    #             color='blue', alpha=0.5, label='Test Residuals')\n",
    "    \n",
    "    # plt.xticks(fontsize=15)\n",
    "    # plt.yticks(fontsize=15)\n",
    "    # plt.xlabel('True Values', fontsize=16)\n",
    "    # plt.axhline(y=0, color='r', linestyle='-')\n",
    "    # plt.title('Residuals')\n",
    "    # plt.legend()\n",
    "    # plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)\n",
    "    # plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "    # plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "    # ax = plt.gca()\n",
    "    # for spine in ax.spines.values():\n",
    "    #     spine.set_linewidth(2.0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801a9ae-b791-49d1-9abf-3b4d76f488ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regressors(X_train, X_val, X_test, y_train, y_val, y_test, \n",
    "                   clfs = ['linear regression', 'ridge', 'LASSO', \n",
    "                           'SVR(linear)', 'SVR(rbf)', 'SVR(poly)', \n",
    "                           'PLSR',\n",
    "                           'Random Forest Regressor', # 'ANN', \n",
    "                           'K-Neighbors Regressor',\n",
    "                           'Gaussian Weighted K-Neighbors Regressor'],\n",
    "                           X_names = None,\n",
    "                           order = False,\n",
    "                           verbose=2):\n",
    "    '''\n",
    "    Run a series of regression models\n",
    "    \n",
    "    Parameters:\n",
    "    -----------    \n",
    "    verbose: \n",
    "        verbose = 0 or False, no intermediate output\n",
    "        verbose = 1, output the last summary table\n",
    "        verbose = 2, also output plots\n",
    "        verbose = 3, output everything\n",
    "    '''\n",
    "\n",
    "    dic_metrics = {}\n",
    "    \n",
    "    for idx, clf_name in enumerate(clfs):\n",
    "\n",
    "        if verbose > 1:\n",
    "            display(HTML('<h2>' + str(idx+1) + '. ' + str(clf_name) + '</h2>'))\n",
    "        if clf_name == 'linear regression':\n",
    "\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "\n",
    "            lr = LinearRegression()\n",
    "            yp = lr.fit(X_train, y_train).predict(X_test)\n",
    "            y_pred_train = lr.predict(X_train)  \n",
    "            best_hparam = 'N/A'\n",
    "\n",
    "        elif clf_name == 'PLSR':\n",
    "            # Partial Least Squares Regression\n",
    "            from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "            hparams = list(range(1, X_train.shape[1])) # Number of components to keep. Should be in [1, n_features]\n",
    "            val_scores = []\n",
    "            for nc in hparams:\n",
    "                plsr = PLSRegression(n_components=nc).fit(X_train, y_train)\n",
    "                val_scores.append(plsr.score(X_val, y_val))\n",
    "\n",
    "            if verbose > 1:\n",
    "                ax = plt.figure().gca()\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                #plt.title('val score ~ components')\n",
    "                plt.xticks(fontsize=15)\n",
    "                plt.yticks(fontsize=15)\n",
    "                plt.xlabel('Components',fontsize=16)\n",
    "                plt.ylabel('Val score',fontsize=16)\n",
    "                # plt.xscale('log')\n",
    "                plt.plot(hparams, val_scores)\n",
    "                plt.scatter(hparams, val_scores, label='components')\n",
    "                plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "                plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "                plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "                # 设置边框加粗\n",
    "                ax = plt.gca()  # 获取当前图形对象\n",
    "                for spine in ax.spines.values():\n",
    "                    spine.set_linewidth(2.0)  # 边框线条加粗\n",
    "                        \n",
    "            best_hparam = hparams[np.argmax(val_scores)]\n",
    "            plsr = PLSRegression(n_components = best_hparam).fit(X_train, y_train)\n",
    "\n",
    "            # print('test score:', ridge.score(X_test, y_test))\n",
    "            yp = plsr.predict(X_test)\n",
    "            y_pred_train = plsr.predict(X_train)\n",
    "            print('Training set R2: ', r2_score(y_train, y_pred_train))\n",
    "            print('Test set R2:', r2_score(y_test, yp))\n",
    "        \n",
    "        else:\n",
    "            print('Undefined regression model: ' + clf_name)\n",
    "\n",
    "        dic_metrics[clf_name] = best_hparam, round(r2_score(y_test, yp), 3), round(mean_squared_error(y_test, yp),3) # save R2 and MSE to dict\n",
    "        \n",
    "        if verbose > 1:\n",
    "            draw_regression_plots(y_train, y_pred_train, y_test, yp, title = clf_name)\n",
    "\n",
    "    if verbose > 0:\n",
    "        display(HTML('<h2>Summary</h2>'))\n",
    "        tbl_html = '<table><tr><th>Regressor</th><th>best hparam</th><th>R2</th><th>MSE</th></tr>'\n",
    "        for k,v in dic_metrics.items():\n",
    "            tbl_html += '<tr><td>'+str(k)+'</td><td>'+str(v[0])+'</td><td>'+str(v[1])+'</td><td>'+str(v[2])+'</td></tr>'\n",
    "        display(HTML( tbl_html + '</table>'))\n",
    "\n",
    "    return dic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118e401-4d92-4d75-94a4-24f54d34271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd8d5e-2d65-42d6-9e7b-e114bdfe2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_indices = [123,122,124,108,86,85,107,125,89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46fc2a-586f-4a3f-ab01-23225c085cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, feature_indices] # 训练集选择的特征\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5304f0-5663-4865-9998-61173679a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cad184-1578-410f-bbf3-1cc5ac2d7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val[:, feature_indices]\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53339cb9-66e8-40b4-a19d-6e9d52c6bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:, feature_indices]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10856abe-96e4-42dc-8d5d-08c811b71fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = [1440.754, 1431.112, 1450.396, 1296.119, 1083.988, 1074.345, 1286.477, 1460.039, 1112.915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db69b8-91ef-4ba0-83b4-d911ab756ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_regressors(X_train, X_val, X_test, y_train, y_val, y_test, clfs = ['PLSR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02305dcf-73b9-4483-9720-80d38e683d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hparams = [.1, 10, 1000, 100000, 10000000]\n",
    "val_scores = []\n",
    "for alpha in hparams:\n",
    "    ridge = Ridge(alpha = alpha).fit(X_train, y_train)\n",
    "    val_scores.append(ridge.score(X_val, y_val))\n",
    "\n",
    "# plt.title('val score ~ alpha')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Alpha',fontsize=16)\n",
    "plt.ylabel('Val score',fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.plot(hparams, val_scores, marker='o')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前图形对象\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.0)  # 边框线条加粗\n",
    "plt.show()\n",
    "\n",
    "best_hparam = hparams[np.argmax(val_scores)]\n",
    "ridge = Ridge(alpha = best_hparam).fit(X_train, y_train)\n",
    "\n",
    "# print('test score:', ridge.score(X_test, y_test))\n",
    "yp = ridge.predict(X_test)\n",
    "ytp = ridge.predict(X_train)\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "print('Training set R2: ', r2_score(y_train, y_pred_train))\n",
    "print('Test set R2:', r2_score(y_test, yp))\n",
    "print('Best param', best_hparam)\n",
    "draw_regression_plots(y_train, ytp, y_test, yp, title = 'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e0944d-54b4-417a-a733-4e840357a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Cs = np.logspace(-3, 3, 60)\n",
    "val_scores = []\n",
    "for C in Cs:\n",
    "    svr = SVR(kernel = 'rbf', C=C).fit(X_train, y_train)\n",
    "    val_scores.append(svr.score(X_val, y_val))\n",
    "\n",
    "# plt.title('val score ~ C')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Val score')\n",
    "plt.xscale('log')\n",
    "plt.plot(Cs, val_scores, marker='o')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "plt.tick_params(axis='y', which='major', left=True, right=False)  \n",
    "plt.show()\n",
    "\n",
    "best_C = Cs[np.argmax(val_scores)]\n",
    "best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561ac7c-93b3-4e84-abe2-4e39a11b11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "gs = np.logspace(-8, -1, 50)\n",
    "val_scores = []\n",
    "for gamma in gs:\n",
    "    svr = SVR(kernel = 'rbf', gamma=gamma).fit(X_train, y_train)\n",
    "    val_scores.append(svr.score(X_val, y_val))\n",
    "\n",
    "# plt.title('val score ~ C')\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('Val score')\n",
    "plt.xscale('log')\n",
    "plt.plot(gs, val_scores, marker='o')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "plt.tick_params(axis='y', which='major', left=True, right=False)  \n",
    "plt.show()\n",
    "\n",
    "best_gamma = gs[np.argmax(val_scores)]\n",
    "best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bf7b7-17a9-4eda-b1fd-006825930470",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel = 'rbf', C=best_C, gamma=best_gamma)\n",
    "yp = svr.fit(X_train, y_train).predict(X_test)\n",
    "ytp = svr.fit(X_train, y_train).predict(X_train)\n",
    "y_pred_train = svr.predict(X_train)\n",
    "print('Training set R2: ', r2_score(y_train, y_pred_train))\n",
    "print('Test set R2:', r2_score(y_test, yp))\n",
    "print('Best C', best_C)\n",
    "print('Best gamma', best_gamma)\n",
    "draw_regression_plots(y_train, ytp, y_test, yp, title = 'SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3986ed6-589a-461d-93a2-a3c3c1a0b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Each run is random. The result is very unstable\n",
    "\n",
    "Ns = [1, 2, 3, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "val_scores = []\n",
    "for N in Ns:\n",
    "    rf_regressor = RandomForestRegressor(n_estimators = N, max_depth = 6, min_samples_split = 4, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "    val_scores.append(rf_regressor.score(X_val, y_val))\n",
    "\n",
    "# plt.title('val score ~ trees')\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Trees',fontsize=16)\n",
    "plt.ylabel('Val score',fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.plot(Ns, val_scores, marker='o')\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "plt.tick_params(axis='y', which='major', left=True, right=False)\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前图形对象\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.0)  # 边框线条加粗\n",
    "plt.show()\n",
    "\n",
    "best_hparam = Ns[np.argmax(val_scores)]\n",
    "rf_regressor = RandomForestRegressor(n_estimators = best_hparam, max_depth = 2)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = rf_regressor.predict(X_train)\n",
    "print('Training set R2: ', r2_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "print('Test set R2:', r2_score(y_test, y_pred))\n",
    "y_tpred = rf_regressor.predict(X_train)\n",
    "\n",
    "print('Best param', best_hparam)\n",
    "draw_regression_plots(y_train, y_tpred, y_test, y_pred, title = 'RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dfe9b-9c44-488d-99ca-5d45e87d47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你已经有 X_train, y_train, X_val, y_val, X_test, y_test 数据\n",
    "\n",
    "Ns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "metrics = ['manhattan', 'euclidean', 'chebyshev']\n",
    "best_score = -np.inf\n",
    "best_hparam = None\n",
    "best_metric = None\n",
    "\n",
    "for metric in metrics:\n",
    "    val_scores = []\n",
    "    for N in Ns:\n",
    "        knr = KNeighborsRegressor(n_neighbors=N, metric=metric).fit(X_train, y_train)\n",
    "        val_score = knr.score(X_val, y_val)\n",
    "        val_scores.append(val_score)\n",
    "        \n",
    "        # 更新最佳参数\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_hparam = N\n",
    "            best_metric = metric\n",
    "\n",
    "    # 绘制当前度量下的验证得分曲线，添加数据点\n",
    "    plt.plot(Ns, val_scores, label=metric, marker='o')\n",
    "\n",
    "# plt.title('Val score ~ neighbors and metrics')\n",
    "plt.xlabel('k',fontsize=16)\n",
    "plt.ylabel('Val score',fontsize=16)\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1.2)  \n",
    "plt.tick_params(axis='x', which='major', bottom=True, top=False) \n",
    "plt.tick_params(axis='y', which='major', left=True, right=False)  \n",
    "plt.legend()\n",
    "\n",
    "# 设置 x 轴刻度为间隔为2\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(range(0, 21, 2))\n",
    "# 设置边框加粗\n",
    "ax = plt.gca()  # 获取当前图形对象\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2.0)  # 边框线条加粗\n",
    "plt.show()\n",
    "\n",
    "# 用最佳超参数在训练集和测试集上评估模型\n",
    "knr = KNeighborsRegressor(n_neighbors=2, metric='euclidean').fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = knr.predict(X_train)\n",
    "print('Training set R2:', r2_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred = knr.predict(X_test)\n",
    "print('Test set R2:', r2_score(y_test, y_pred))\n",
    "y_tpred = knr.predict(X_train)\n",
    "print('Best param', best_hparam)\n",
    "# 假设 draw_regression_plots 是一个已经定义的函数\n",
    "draw_regression_plots(y_train, y_tpred, y_test, y_pred, title=f'$k$-NNR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b57f9-e13a-498d-aead-4621e48e20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GaussianWeightedKNNRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, n_neighbors=80, sigma=1.0, epsilon=0.5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.sigma = sigma\n",
    "        self.epsilon = epsilon\n",
    "        self.knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.knn.fit(X_train, y_train)\n",
    "    \n",
    "    def _gaussian_weights(self, distances):\n",
    "        distances = np.where(distances == 0, self.epsilon, distances)  # 将距离为0的位置替换为epsilon\n",
    "        #print(\"Distances:\", distances)\n",
    "        #distances /= 100  # 将距离除以100\n",
    "        #print(\"Distances:\", distances)\n",
    "        weights = np.exp(-distances**2 / (2 * self.sigma**2))\n",
    "        #print(\"Weights:\", weights)\n",
    "        return weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions=[]\n",
    "        \n",
    "        for query_point in X:\n",
    "            #print(\"X\", X)\n",
    "            distances, indices = self.knn.kneighbors(query_point.reshape(1, -1))\n",
    "            weights = self._gaussian_weights(distances/np.max(distances))\n",
    "            normalized_weights = weights / np.sum(weights)\n",
    "            weighted_sum = np.sum(normalized_weights * self.y_train[indices.flatten()])\n",
    "            predictions.append(weighted_sum)\n",
    "            \n",
    "        return np.array(predictions)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return r2_score(y, self.predict(X))\n",
    "    \n",
    "    def gridsearch_hparam(X_train, y_train, X_val = None, y_val = None, ks = [3,4,5,10,15,16,17,18,19,20,21,22,23,24,25,30,35,40], sigmas=[.1,.2,.25,.3,1,10,100,1000]):\n",
    "        \n",
    "        best_r2 = -np.inf\n",
    "        best_clf = None\n",
    "        best_predictions = None\n",
    "\n",
    "        hparams = [ks, sigmas]\n",
    "        \n",
    "        for k, sigma in tqdm(itertools.product(*hparams)):\n",
    "            \n",
    "            clf = GaussianWeightedKNNRegressor(k, sigma)\n",
    "\n",
    "            if X_val is None or y_val is None:\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2, shuffle=True, random_state=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            score = r2_score(y_val, clf.predict(X_val))            \n",
    "\n",
    "            # print(k, sigma, score)\n",
    "            if score > best_r2:\n",
    "                best_r2 = score\n",
    "                best_clf = clf\n",
    "        \n",
    "        return best_clf\n",
    "\n",
    "gwknr = GaussianWeightedKNNRegressor.gridsearch_hparam(X_train, y_train, X_val, y_val) \n",
    "# print(gwknr.__dir__)\n",
    "best_hparam = gwknr.n_neighbors, gwknr.sigma\n",
    "\n",
    "y_pred_train = gwknr.predict(X_train)\n",
    "print('Training set R2: ', r2_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred = gwknr.predict(X_test)\n",
    "print('Test set R2:', r2_score(y_test, y_pred))\n",
    "y_tpred = gwknr.predict(X_train)\n",
    "print('Best param', best_hparam)\n",
    "\n",
    "draw_regression_plots(y_train, y_tpred, y_test, y_pred, title = 'G$k$-NNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e5d77-4d0f-4c19-a1fd-8dc2a38cf4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
